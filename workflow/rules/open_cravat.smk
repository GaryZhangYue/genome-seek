# Functions and rules for running OpenCRAVAT
from scripts.common import abstract_location, allocated


rule chrom_selectvariants:
    """
    Makes per-chromosome jointly called, normalized VCFs from GLnexus output.
    This step is used to speed up the remaining OpenCRAVAT rules. At the end, 
    the resulting SQL-lite databases are merged back together (gather-step) 
    for each chromosome.
    @Input:
        Multi-sample joint, normalized VCF file (scatter)
    @Output:
        Chromosome chunked joint, normalized VCF file
    """
    input: 
        vcf = join(workpath, "deepvariant", "VCFs", "joint.glnexus.norm.vcf.gz"),
    output: 
        vcf = join(workpath, "OpenCRAVAT", "VCFs", "{chunk}.germline.vcf.gz"),
    params: 
        rname  = "chrselect",
        genome = config['references']['GENOME'], 
        chrom  = "{chunk}", 
        memory = allocated("mem", "chrom_selectvariants", cluster).rstrip('G')
    message: "Running Chromosome SelectVariants on '{input.vcf}' input file"
    threads: int(allocated("threads", "chrom_selectvariants", cluster))
    envmodules: 
        config['tools']['gatk4'], config['tools']['bcftools']
    shell: """
    gatk --java-options '-Xmx{params.memory}g -XX:ParallelGCThreads={threads}' SelectVariants \\
        -R {params.genome} \\
        --variant {input.vcf} \\
        -L {params.chrom} \\
        --exclude-non-variants \\
        --output {output.vcf}
    
    tabix --force \\
        -p vcf {output.vcf}
    """


rule open_cravat:
    """
    Performs genomic variant interpretation including variant impact, annotation,
    and scoring using OpenCRAVAT. Creates a SQL-lite database that can be used 
    with OpenCRAVAT's user interface. Here is more information about OpenCRAVAT: 
    https://open-cravat.readthedocs.io/en/latest/
    @Input:
        Chromosome chunked joint, normalized VCF file (scatter)
    @Output:
        Chromosome chunked SQL-lite OpenCravat results
    """
    input: 
        vcf = join(workpath, "OpenCRAVAT", "VCFs", "{chunk}.germline.vcf.gz"),
    output: 
        db = join(workpath, "OpenCRAVAT", "cravat_{chunk}.sqlite"),
    params: 
        rname  = "cravat",
        prefix = "cravat_{chunk}",
        outdir = join(workpath, "OpenCRAVAT"),
        annot  = ' '.join(config['options']['oc_annotators']),
        genome = config['references']['OC_LIFTOVER'],
        module = config['references']['OC_MODULES'],
    message: "Running OpenCRAVAT run on '{input.vcf}' input file"
    threads: int(allocated("threads", "open_cravat", cluster))
    envmodules: config['tools']['open_cravat']
    shell: """
    oc run \\
        -t vcf \\
        -x \\
        --newlog \\
        --cleanrun \\
        --system-option "modules_dir={params.module}" \\
        -a {params.annot} \\
        -n {params.prefix} \\
        -l {params.genome} \\
        -d {params.outdir} \\
        --mp {threads} \\
        {input.vcf}
    """


# TODO: convert this into a script
rule cravat_filter:
    """
    Performs additional filtering on the SQL-lite file generated by OpenCRAVAT.
    The filter options provided by OpenCRAVAT were not working correctly. An issue
    with the maintainers of the tool have been opened up. This rule is effectively
    a patch and may not be used in the near future. Each script that is generated
    performs additional rounds of filtering. 

    @filter_1: Filters variants based on sequence ontology and allele frequency 
    in public databases.
        @criteria: 
        Sequence ontology one of the given list of SO in the config file
            AND
        GNOMAD AF < 0.001 OR GNOMAD3 AF < 0.001 OR 1000Genome AF < 0.001 
            OR 
        all GNOMAD, GNOMAD3 and 1000Genome AF are missing
    
    @filter_2: Filter variants based on criteria given in the config.json 
    "secondary" group. To add filter move an annotator from "notused" group 
    to "secondary" group. Additional filter criterion can be added in the 
    config.json in the folloing format:
        "annotator": {
            "col" : "column of annotator to use"
            "relation" : "<, <=, >, >="  # for numeric values or "IN" for character values
            "value": "value to use for filter"
        }
    Note, if multiple column of same annotator need to be used for filtering using the 
    following format:
        "annotator": {
            "col": "multiple",
            "cols" : "col1,col2",
            "relation": "relation1,relation2",
            "value": "value1,value2"
        }
    
    @fix_column: By default, OpenCRAVAT has vcf_info total reads as string that includes 
    reads from all the samples that contains the variant. This rule creates an additional
    column with max and min of total reads and max and min of AF.
    @Input:
        Chromosome chunked SQL-lite OpenCravat results
    @Output:
        Filtered, fixed chromosome chunked SQL-lite OpenCravat results
    """
    input: 
        db = join(workpath, "OpenCRAVAT", "cravat_{chunk}.sqlite"),
    output:
        filter_1 = join(workpath, "OpenCRAVAT", "filter", "cravat_{chunk}.f1.sqlite"),
        filter_2 = join(workpath, "OpenCRAVAT", "filter", "cravat_{chunk}.f2.sqlite"),
        fixed = join(workpath, "OpenCRAVAT", "filter", "cravat_{chunk}.fixed.sqlite"),
    params: 
        rname  = "ocfilter",
        chrom  = "{chunk}",
        scripts  = join(workpath, "OpenCRAVAT", "scripts"),
        filter_1 = join(workpath, "OpenCRAVAT", "scripts", "filter_1_{chunk}.py"),
        filter_2 = join(workpath, "OpenCRAVAT", "scripts", "filter_2_{chunk}.py"),
        fixed = join(workpath, "OpenCRAVAT", "scripts", "fix_column_{chunk}.py"),
        maf_thres = config['options']['cravat_filters']['primary']['maf'],
        so = config['options']['cravat_filters']['primary']['so'],
        secondary = config['options']['cravat_filters']['secondary'],
    message: "Running OpenCRAVAT filters on '{input.db}' input file"
    threads: int(allocated("threads", "open_cravat", cluster))
    envmodules: 
        # Requires sqlite3, added in python/3.5
        config['tools']['python3']
    shell: """
# Create first filtering script,
# Filters based on AF 
mkdir -p {params.scripts}
cp {input.db} {output.filter_1} 
cat << EOF > {params.filter_1}
import sqlite3
import os

maf = {params.maf_thres}
mafc = str(1 - float({params.maf_thres}))
so = "{params.so}"
conn = sqlite3.connect("{output.filter_1}")
conn.isolation_level = None
cursor = conn.cursor()
conn.execute('CREATE TABLE variant2 AS SELECT * FROM variant WHERE (base__so IN (' + '"' + '", "'.join(so.split(',')) + '"' + ')) AND ((gnomad__af IS NULL AND gnomad3__af IS NULL AND thousandgenomes__af IS NULL) OR (gnomad__af <= ' + maf +' OR gnomad__af >= '+mafc+' OR gnomad3__af <= '+maf+' OR gnomad3__af >= '+mafc+' OR thousandgenomes__af <= '+maf+' OR thousandgenomes__af >= '+mafc+'))')
conn.execute('DROP TABLE variant')
conn.execute('ALTER TABLE variant2 RENAME TO variant')
conn.execute('DELETE from sample WHERE base__uid NOT IN (SELECT base__uid FROM variant)')
conn.execute('DELETE FROM gene WHERE base__hugo NOT IN (SELECT base__hugo FROM variant)')
conn.execute('DELETE FROM mapping WHERE base__uid NOT IN (SELECT base__uid FROM variant)')
conn.execute('UPDATE info SET colval = (SELECT COUNT(*) FROM variant) WHERE colkey == "Number of unique input variants"')
conn.execute('VACUUM')
conn.close()
EOF

# Create second filtering script,
# Filters based on filters in config
cp {output.filter_1} {output.filter_2}
cat << EOF > {params.filter_2}
import sqlite3
import os

conn = sqlite3.connect("{output.filter_2}")
conn.isolation_level = None
cursor = conn.cursor()
filter = {params.secondary}
        
def filtercol(dd, annot):
    if dd['relation']=='IN':
        return annot + '__' + dd['col'] + ' ' + dd['relation'] + ' ("' + '", "'.join(dd['value'].split(',')) + '")'
    elif dd['relation']=='IS' or dd['relation']=='IS NOT':
        return annot + '__' + dd['col'] + ' ' + dd['relation'] + ' ' + dd['value']
    else:
        return annot + '__'+ dd['col'] + ' ' + dd['relation'] + dd['value']    

def filterunit(annot):
    dd = filter[annot]
    if dd['col'].lower()=='multiple':
        cols = dd['cols'].split(',')
        relations = dd['relation'].split(',')
        values = dd['value'].split(',')
        return(' OR '.join([filtercol({{'col':cols[0], 'relation': relations[0], 'value': values[0]}}, annot) for i in range(len(cols))]))
    else:
        return(filtercol(dd, annot))

    
def filterunit_null(annot):
    dd = filter[annot]
    if dd['col'].lower()=='multiple':
        cols = dd['cols'].split(',')
        relations = dd['relation'].split(',')
        values = dd['value'].split(',')
        return(' AND '.join([annot + '__' + cols[i] + ' IS NULL' for i in range(len(cols))]))
    else:
        return(annot + '__' + dd['col'] + ' IS NULL')
        
filter_query_nonnull = ' OR '.join([filterunit(annot) for annot in filter.keys()])
filter_query_null = ' AND '.join([filterunit_null(annot) for annot in filter.keys()])
filter_query = filter_query_nonnull + ' OR (' + filter_query_null + ')'
print(filter_query)
conn.execute('CREATE TABLE variant2 AS SELECT * FROM variant WHERE (' + filter_query + ')')
conn.execute('DROP TABLE variant')
conn.execute('ALTER TABLE variant2 RENAME TO variant')
conn.execute('DELETE from sample WHERE base__uid NOT IN (SELECT base__uid FROM variant)')
conn.execute('DELETE FROM gene WHERE base__hugo NOT IN (SELECT base__hugo FROM variant)')
conn.execute('DELETE FROM mapping WHERE base__uid NOT IN (SELECT base__uid FROM variant)')
conn.execute('UPDATE info SET colval = (SELECT COUNT(*) FROM variant) WHERE colkey == "Number of unique input variants"')
conn.execute('VACUUM')
conn.close()
EOF
    
# Create fix column script,
# Fixes columns to a min and max AF 
cp {output.filter_2} {output.fixed}
cat << EOF > {params.fixed}
import sqlite3
import os
import pandas as pd

conn = sqlite3.connect("{output.fixed}")
conn.isolation_level = None
cursor = conn.cursor()
depth = pd.read_sql_query('SELECT base__uid,vcfinfo__tot_reads,vcfinfo__af from variant', conn, index_col = 'base__uid')
tot_read = depth.vcfinfo__tot_reads.str.split(';', expand = True).astype('float')
af = depth.vcfinfo__af.str.split(';', expand = True).apply(pd.to_numeric)
depth['vcfinfo__Max_read'] = tot_read.max(axis = 1)
depth['vcfinfo__Min_read'] = tot_read.min(axis = 1)
depth['vcfinfo__Max_af'] = af.max(axis = 1)
depth['vcfinfo__Min_af'] = af.min(axis = 1)
depth.to_sql('tmp', conn, if_exists = 'replace', index = True)
conn.execute('alter table variant add column vcfinfo__Max_read numeric(50)')
conn.execute('alter table variant add column vcfinfo__Min_read numeric(50)')
conn.execute('alter table variant add column vcfinfo__Max_af numeric(50)')
conn.execute('alter table variant add column vcfinfo__Min_af numeric(50)')
qry = 'update variant set vcfinfo__Max_read = (select vcfinfo__Max_read from tmp where tmp.base__uid = variant.base__uid) where vcfinfo__Max_read is NULL'
conn.execute(qry)
qry = 'update variant set vcfinfo__Min_read = (select vcfinfo__Min_read from tmp where tmp.base__uid = variant.base__uid) where vcfinfo__Min_read is NULL'
conn.execute(qry)
qry = 'update variant set vcfinfo__Max_af = (select vcfinfo__Max_af from tmp where tmp.base__uid = variant.base__uid) where vcfinfo__Max_af is NULL'
conn.execute(qry)
qry = 'update variant set vcfinfo__Min_af = (select vcfinfo__Min_af from tmp where tmp.base__uid = variant.base__uid) where vcfinfo__Min_af is NULL'
conn.execute(qry)
conn.execute('''INSERT INTO variant_header (col_name, col_def) VALUES ('vcfinfo__Max_read','{{"index": null, "name": "vcfinfo__Max_read", "title": "Max reads", "type": "float", "categories": [], "width": 70, "desc": null, "hidden": false, "category": null, "filterable": true, "link_format": null, "genesummary": false, "table": false}}')''')
conn.execute('''INSERT INTO variant_header (col_name, col_def) VALUES ('vcfinfo__Min_read','{{"index": null, "name": "vcfinfo__Min_read", "title": "Min reads", "type": "float", "categories": [], "width": 70, "desc": null, "hidden": false, "category": null, "filterable": true, "link_format": null, "genesummary": false, "table": false}}')''')
conn.execute('''INSERT INTO variant_header (col_name, col_def) VALUES ('vcfinfo__Max_af','{{"index": null, "name": "vcfinfo__Max_af", "title": "Max AF", "type": "float", "categories": [], "width": 70, "desc": null, "hidden": false, "category": null, "filterable": true, "link_format": null, "genesummary": false, "table": false}}')''')
conn.execute('''INSERT INTO variant_header (col_name, col_def) VALUES ('vcfinfo__Min_af','{{"index": null, "name": "vcfinfo__Min_af", "title": "Min AF", "type": "float", "categories": [], "width": 70, "desc": null, "hidden": false, "category": null, "filterable": true, "link_format": null, "genesummary": false, "table": false}}')''')
conn.commit()
conn.execute('drop table tmp')
conn.execute('VACUUM')
conn.close()
EOF
    
echo 'Running first filtering script'
python3 {params.filter_1}

echo 'Running secondary filtering script'
python3 {params.filter_2}

echo 'Running column fixing script'
python3 {params.fixed}
"""


rule merge_sqlite:
    """
    Merges the filtered, chromosone chunked SQL-lite files. The OpenCRAVAT run 
    command was scattered on each chromosomes (creating chunks) to speed up its
    run time. The step merges the resulting filtered, chunked SQL-lite objects 
    into one SQL-lite file. This creates the final SQL-lite file that can be 
    used with OpenCRAVAT's user interface.
    @Input:
        Filtered, fixed chromosome chunked SQL-lite OpenCravat results (gather)
    @Output:
        Merged and filtered SQL-lite OpenCravat results
    """
    input: 
        dbs = expand(join(workpath, "OpenCRAVAT", "filter", "cravat_{chunk}.fixed.sqlite"), chunk=chunks),
    output: 
        merged = join(workpath, "OpenCRAVAT", "cravat.merged.sqlite"),
    params: 
        rname  = "ocmerge",
    message: "Running OpenCRAVAT mergesqlite on '{input.dbs}' input files"
    threads: int(allocated("threads", "merge_sqlite", cluster))
    envmodules: config['tools']['open_cravat']
    shell: """
    oc util mergesqlite \\
        -o {output.merged} \\
        {input.dbs} 
    """